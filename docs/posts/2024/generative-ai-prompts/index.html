<!DOCTYPE html>
<html lang="en">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    

    
    <link rel="preconnect" href="https://www.googletagmanager.com" />
    <link rel="preconnect" href="https://www.google-analytics.com" />

    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=G-97N9TLJ517"
    ></script>
    <script async>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());

      gtag("config", "G-97N9TLJ517");
    </script>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8206710020783397"
    crossorigin="anonymous"></script>
    <meta name="google-adsense-account" content="ca-pub-8206710020783397">
    

    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="StatWizard: Access beginner-friendly blog posts covering various applications of statistics, data science, computer programming and finance. Also hosts the personal website of the author, Subhrajyoty Roy."
    />
    <link rel="icon" href="/images/logo.png" />
    <title>
Designing Prompts: Generative AI Series - Part 3
</title>

    

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel="stylesheet">


<script src="https://code.jquery.com/jquery-3.7.0.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css">




<link rel="stylesheet" type="text/css" href="//localhost:1313/css/index.1337d74e098520f28fd7366058958938.css" />






<script src="https://unpkg.com/typed.js@2.0.16/dist/typed.umd.js"></script>


<style>
  html {
      scroll-behavior: smooth;
  }
  
  .roboto-thin {
    font-family: "Roboto", sans-serif;
    font-weight: 100;
    font-style: normal;
  }

  .roboto-light {
    font-family: "Roboto", sans-serif;
    font-weight: 300;
    font-style: normal;
  }

  .roboto-regular {
    font-family: "Roboto", sans-serif;
    font-weight: 400;
    font-style: normal;
  }

  .roboto-medium {
    font-family: "Roboto", sans-serif;
    font-weight: 500;
    font-style: normal;
  }

  .roboto-bold {
    font-family: "Roboto", sans-serif;
    font-weight: 700;
    font-style: normal;
  }

  .roboto-black {
    font-family: "Roboto", sans-serif;
    font-weight: 900;
    font-style: normal;
  }

  .roboto-thin-italic {
    font-family: "Roboto", sans-serif;
    font-weight: 100;
    font-style: italic;
  }

  .roboto-light-italic {
    font-family: "Roboto", sans-serif;
    font-weight: 300;
    font-style: italic;
  }

  .roboto-regular-italic {
    font-family: "Roboto", sans-serif;
    font-weight: 400;
    font-style: italic;
  }

  .roboto-medium-italic {
    font-family: "Roboto", sans-serif;
    font-weight: 500;
    font-style: italic;
  }

  .roboto-bold-italic {
    font-family: "Roboto", sans-serif;
    font-weight: 700;
    font-style: italic;
  }

  .roboto-black-italic {
    font-family: "Roboto", sans-serif;
    font-weight: 900;
    font-style: italic;
  }
</style>


<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css"/> 
      
     
  </head>
  <body>
    <div class="app-container min-h-[100vh] flex flex-col justify-between">
      <nav class="bg-white shadow-xl z-50">
  
  <div class="hidden md:flex w-full py-2 px-4 md:px-6 lg:px-8 md:flex flex-row items-center justify-between">
    
    <div class="flex flex-row justify-start items-center gap-4">
      
      <a
        href="/"
        class="px-4 py-2 box-border rounded-t-lg hover:bg-gray-100 hover:border-b-2 hover:border-blue-600 hover:text-blue-600 roboto-medium"
      >
        Home
      </a>
      
      <a
        href="/posts"
        class="px-4 py-2 box-border rounded-t-lg hover:bg-gray-100 hover:border-b-2 hover:border-blue-600 hover:text-blue-600 roboto-medium"
      >
        Blog
      </a>
      
      <a
        href="/research"
        class="px-4 py-2 box-border rounded-t-lg hover:bg-gray-100 hover:border-b-2 hover:border-blue-600 hover:text-blue-600 roboto-medium"
      >
        Research
      </a>
      
      <a
        href="/collection"
        class="px-4 py-2 box-border rounded-t-lg hover:bg-gray-100 hover:border-b-2 hover:border-blue-600 hover:text-blue-600 roboto-medium"
      >
        Collection
      </a>
      
      <a
        href="/cv"
        class="px-4 py-2 box-border rounded-t-lg hover:bg-gray-100 hover:border-b-2 hover:border-blue-600 hover:text-blue-600 roboto-medium"
      >
        CV
      </a>
      
      <a
        href="/contact"
        class="px-4 py-2 box-border rounded-t-lg hover:bg-gray-100 hover:border-b-2 hover:border-blue-600 hover:text-blue-600 roboto-medium"
      >
        Contact
      </a>
      
    </div>


    
    <div class="w-[200px] flex flex-row justify-around items-center">
      
      <a
        href="mailto:subhrajyotyroy@gmail.com"
        class="hover:text-blue-600 transition-all ease-in-out"
        aria-label="fas fa-envelope for link mailto:subhrajyotyroy@gmail.com"
        target="_blank"
      >
        <i class="fas fa-envelope fa-lg"></i>
      </a>
      
      <a
        href="https://github.com/subroy13"
        class="hover:text-blue-600 transition-all ease-in-out"
        aria-label="fab fa-github for link https://github.com/subroy13"
        target="_blank"
      >
        <i class="fab fa-github fa-lg"></i>
      </a>
      
      <a
        href="https://www.linkedin.com/in/subroy13"
        class="hover:text-blue-600 transition-all ease-in-out"
        aria-label="fab fa-linkedin-in for link https://www.linkedin.com/in/subroy13"
        target="_blank"
      >
        <i class="fab fa-linkedin-in fa-lg"></i>
      </a>
      
      <a
        href="https://scholar.google.com/citations?user=Gocm0lYAAAAJ&amp;hl=en&amp;authuser=1"
        class="hover:text-blue-600 transition-all ease-in-out"
        aria-label="fab fa-google-scholar for link https://scholar.google.com/citations?user=Gocm0lYAAAAJ&amp;hl=en&amp;authuser=1"
        target="_blank"
      >
        <i class="fab fa-google-scholar fa-lg"></i>
      </a>
      
      <a
        href="#"
        class="hover:text-blue-600 transition-all ease-in-out"
        aria-label="fab fa-instagram for link #"
        target="_blank"
      >
        <i class="fab fa-instagram fa-lg"></i>
      </a>
      
      <a
        href="https://www.facebook.com/subroy13/"
        class="hover:text-blue-600 transition-all ease-in-out"
        aria-label="fab fa-facebook for link https://www.facebook.com/subroy13/"
        target="_blank"
      >
        <i class="fab fa-facebook fa-lg"></i>
      </a>
      
    </div>
  </div>
  

  
  <div class="w-full mx-0 flex flex-col gap-0 md:hidden">
    <div class="w-full mx-0 flex flx-row px-2 py-4 justify-between items-center">
      
      <div class="w-[200px] flex items-center">
        <a
          class="uppercase font-extrabold font-mono text-2xl flex flex-row justify-center items-center gap-2"
          href="/"
        >
          <img
            src="/images/logo-wide-2.png"
            height="75px"
            width="150px"
            class="inline-block"
            alt="StatWizard Logo"
          />
        </a>
      </div>

      
      <div class="w-[30px] mr-4">
        <button 
          type="button"
          id="mobile-menu-button"
          class="inline-flex items-center justify-center rounded-md p-2 text-gray-400 hover:text-white outline-none"
          aria-controls="mobile-menu"
          aria-expanded="false"
        >
          <span class="sr-only">Open main menu</span>
          
          <svg
            id="mobile-menu-close-icon"
            class="bg-white text-neutral-800 outline-none block h-6 w-6"
            fill="none"
            viewBox="0 0 24 24"
            stroke-width="1.5"
            stroke="currentColor"
            aria-hidden="true"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"
            />
          </svg>
          
          <svg
            id="mobile-menu-open-icon"
            class="bg-white text-neutral-800 outline-none hidden h-6 w-6"
            fill="none"
            viewBox="0 0 24 24"
            stroke-width="1.5"
            stroke="currentColor"
            aria-hidden="true"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              d="M6 18L18 6M6 6l12 12"
            />
          </svg>
        </button>
      </div>
    </div>

    
    <div id="mobile-menu" class="bg-white w-full mx-0 hidden">
      <ul class="flex flex-col gap-2">
        
        <li
          class="px-4 py-2 box-border hover:bg-gray-100 hover:text-blue-600 hover:border-b-2 hover:border-blue-600"
        >
          <a href="/" class=""> Home </a>
        </li>
        
        <li
          class="px-4 py-2 box-border hover:bg-gray-100 hover:text-blue-600 hover:border-b-2 hover:border-blue-600"
        >
          <a href="/posts" class=""> Blog </a>
        </li>
        
        <li
          class="px-4 py-2 box-border hover:bg-gray-100 hover:text-blue-600 hover:border-b-2 hover:border-blue-600"
        >
          <a href="/research" class=""> Research </a>
        </li>
        
        <li
          class="px-4 py-2 box-border hover:bg-gray-100 hover:text-blue-600 hover:border-b-2 hover:border-blue-600"
        >
          <a href="/collection" class=""> Collection </a>
        </li>
        
        <li
          class="px-4 py-2 box-border hover:bg-gray-100 hover:text-blue-600 hover:border-b-2 hover:border-blue-600"
        >
          <a href="/cv" class=""> CV </a>
        </li>
        
        <li
          class="px-4 py-2 box-border hover:bg-gray-100 hover:text-blue-600 hover:border-b-2 hover:border-blue-600"
        >
          <a href="/contact" class=""> Contact </a>
        </li>
        
      </ul>
    </div>
  </div>
  
</nav>


      <div class="content-container mx-0 px-0">
        



    <div class="relative h-[50vh] max-h-[300px] w-full bg-cover bg-center bg-no-repeat bg-fixed rounded-b-md" 
        style = "background-image: url('//localhost:1313/posts/2024/generative-ai-prompts/featured.webp')">
        
            <div class = "absolute top-0 left-0 bg-neutral-800/100 w-fit text-white p-1 ml-1 font-xs rounded-md">
                <p>Cover image taken from <a href="https://www.unstability.ai/">Unstable Diffusion</a></p>
            </div>
        
    </div>



<div class="mt-4 flex flex-col gap-4 mx-2 px-2 md:mx-4 md:px-8">
    <h1 class="text-3xl text-center text-neutral-600 font-bold md:px-8 md:pt-6">
        Designing Prompts: Generative AI Series - Part 3
    </h1>
    <div class="m-2 p-4 rounded-lg shadow-lg border-2">
        <div class="grid grid-cols-1 md:grid-cols-2 gap-4">
            <div class="flex flex-col justify-center items-center gap-2">   
                <div class="mt-1 flex flex-row text-neutral-800 gap-4">
                    <p class="font-bold">Date:</p>
                    <p class="font-normal">17 May, 2024</p>
                </div> 
                <p class="mt-1 text-neutral-600">
                    <span class="font-bold">10</span> minutes read
                </p>
                <div class="my-1">
                    
                        <a href="//localhost:1313/tags/artificial-intelligence/" 
                            class = "inline-block bg-gray-200 rounded-full px-3 py-1 text-sm font-base text-gray-700 mr-2 mb-2
                            hover:underline hover:bg-gray-300 transition ease-in-out">
                            Artificial Intelligence
                        </a>
                    
                        <a href="//localhost:1313/tags/deep-learning/" 
                            class = "inline-block bg-gray-200 rounded-full px-3 py-1 text-sm font-base text-gray-700 mr-2 mb-2
                            hover:underline hover:bg-gray-300 transition ease-in-out">
                            Deep Learning
                        </a>
                    
                        <a href="//localhost:1313/tags/generative-ai/" 
                            class = "inline-block bg-gray-200 rounded-full px-3 py-1 text-sm font-base text-gray-700 mr-2 mb-2
                            hover:underline hover:bg-gray-300 transition ease-in-out">
                            Generative AI
                        </a>
                    
                </div>    
            </div>
            <div class="flex flex-col justify-start gap-2">
                <h1 class="text-lg font-bold">Prerequisites</h1>
                <ul class="space-y-2 text-left">
                    
                    <li class="flex items-center space-x-3">
                        <svg class="flex-shrink-0 w-3 h-3 text-green-500" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 16 12">
                            <path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M1 5.917 5.724 10.5 15 1.5"/>
                        </svg>
                        <span>Probability - </span>
                        
                            <span class="text-green-600 font-semibold">Beginner</span>
                        
                    </li>
                    
                </ul>
            </div>    
        </div>
        <p class="mt-4 p-4 text-sm">
            <span class="font-semibold">Summary: </span> This is a series of blog posts on Generative AI and Prompting Techniques. In this post of Generative AI series, we will look into what prompt engineering is, and how to design better prompts to leverage the power of Generative AI in your typical use-cases.
        </p>
    </div>
    <div class="grid grid-cols-1 md:grid-cols-4 gap-2">
        <div class="relative col-span-1">
            <div class="sticky top-0 left-0 w-full pl-4 pt-4">
                <h1 class="text-bold text-xl">Table of Contents</h1>
                <div class="prose">
                    <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#prompt-engineering">Prompt Engineering</a></li>
    <li><a href="#prompting-techniques">Prompting Techniques</a>
      <ul>
        <li><a href="#chatbot-assistant">Chatbot Assistant</a></li>
        <li><a href="#more-instructions-and-prompt-templating">More Instructions and Prompt Templating</a></li>
        <li><a href="#system-prompts">System Prompts</a></li>
      </ul>
    </li>
    <li><a href="#conclusion">Conclusion</a></li>
  </ul>
</nav>
                </div>
            </div>
        </div>
        <div class="col-span-3">
            <div class="text-justify break-words w-full">
                <div class="prose" style="max-width: none;">
                    <h2 id="introduction">Introduction</h2>
<p>In the last post (check <a href="https://www.statwizard.in/posts/2024/generative-ai-encoder-decoder/">here</a> if you haven’t already) of the Generative AI series, we look at how the encoder-decoder type of generative AI models work, and also how we can use the hyperparameters to tune the sampling procedure of the decoder, enabling us to make the generative AI useful.</p>
<p>In this post, we will look at the other side of the coin: how we can make effective use of the encoder to make generative AI useful.</p>
<p><em>Note: There are some paragraphs where I have highlighted them in yellow, you might want to skip those if you think math is too boring or too hard!</em></p>
<h2 id="prompt-engineering">Prompt Engineering</h2>
<p>Before proceeding with how to make effective use of a generative AI model’s “encoder”, let’s take a step back and think of how we can tune the encoder. The encoder only acts on your input text and tries to create a comprehensive understanding of your instructions. There is not much you can do here, either you can retrain the encoder to gain a better understanding of your domain knowledge through <strong>“fine-tuning”</strong>, or, effectively communicate your intentions through the input text to the encoder. This effective communication is <strong>“prompt engineering”</strong>.</p>
<p>Let me give you an example: Think of yourself giving a presentation, let’s say on “cooking fish”. The encoder is like the part of your brain that processes the concepts associated with that topic, it basically is the experience you have accumulated by cooking fish probably hundreds of times. On the other hand, the decoder is the part of your brain that you use to explain and give the presentation to your audience. Now, based on your audience, you can tune your “decoder”-brain to stylize your presentation: If the audiences are chefs, then you would want to provide details about different spices you use to cook the fish; but if the audiences are nutritionists, then you would want to provide details on the nutritional value of different fishes. Compared to that, the “encoder”-brain has only two ways to do something new:</p>
<ul>
<li>
<p>By cooking and gathering more experience. This is fine-tuning.</p>
</li>
<li>
<p>By attending some seminars on cooking (by similar professionals as of your audience) and using that information in your presentation. This is prompt engineering.</p>
</li>
</ul>
<p>Formally,</p>
<blockquote>
<p>Prompt Engineering is designing the input to the generative AI models in a way to ensure better performance in the generated output for specific needs and use-cases.</p>
</blockquote>
<h2 id="prompting-techniques">Prompting Techniques</h2>
<p>Prompting techniques are some empirically proven guidelines on how one can achieve better results through custom-made prompts.</p>
<h3 id="chatbot-assistant">Chatbot Assistant</h3>
<p>The LLM (Large Language Models) as a whole, is an impressive machine to autocomplete texts, nothing more. To me, this is the most accurate way to understand LLM.</p>
<p>Normally, we think of autocompleting like this.</p>
<pre tabindex="0"><code>Once upon a time, there was a ____
</code></pre><p>and then LLM can fill up the blank by predicting the next word. It does so because it can understand that this is probably the starting line of a fiction story because it has seen so many stories that start with the exact same line in its training data.</p>
<p>However, a more useful structure would be if the LLM could answer the questions asked by us humans. Or perform the explicit instructions given by us. So, the researchers tried training the models (more like fine-tuned) on documents like this:</p>
<pre tabindex="0"><code>User: What is the capital of France?
Assistant: The capital of France is Paris.
User: Which visiting places should I go to in Paris?
Assistant: Here are some of the top recommended visiting places in Paris: 1. Effiel Tower. 2. Louvre Museum. 3. Notre-Dame Cathedral, …
</code></pre><p>Now since it has been trained on a lot of documents that look like this, once we pass some query “What is 2+2?”, under the hood, one can send the LLM model the following text:</p>
<pre tabindex="0"><code>User: What is 2+2?
Assistant: _________
</code></pre><p>and ask the LLM to complete this sentence/paragraph. As in the training documents, it saw that the expected behaviour here is to answer the previous question asked after that “User:” word, so now it knows it can only be completed with 2+2 is 4.</p>
<p>This kind of training is usually called “instruction fine-tuning” of the model.</p>
<p>This is what happens under the hood when you use <a href="https://chat.openai.com/">ChatGPT</a>.</p>
<h3 id="more-instructions-and-prompt-templating">More Instructions and Prompt Templating</h3>
<p>Now, as soon as these LLMs were unleashed onto the world, many users tried to experiment with its behaviour by carefully changing the instructions they give in the user query after that User: keyword. They also found that many common instructions exist that can serve as a template. the only changing part is probably the final query asked. As an example consider the following:</p>
<pre tabindex="0"><code>Provide a step-by-step guide on how to prepare a delicious dish based on the ingredients which I list down below. Please include the following in your response.
1. The name of the dish.
2. A list of integredients needed (including the quantities)
3. How much approximate time will be required to make it.
4. Finally the receipe on the step-by-step process on how to prepare the dish.
Also make sure the dish has nutritional value.
Here are the list of available ingredients:
{list of ingredients}
</code></pre><p>This can serve as a template whenever one is asking for a new recipe. The format and the template would remain the same, only the list of ingredients may change from time to time and based on the person who is asking it. So, it is now possible to build software that takes input from users about the list of ingredients and pastes them in <code>{list of ingredients}</code> before calling the LLM, making the software capable of using AI.</p>
<div class="mermaid">
graph LR
    User --> ApplicationCode[Application Code]
    ApplicationCode --> Variable
    Template --> Prompt
    Variable --> Prompt
    Prompt --> LLM
</div>
<p>So, I used this prompt with the following list of ingredients: rice, eggplant, tomatoes, flour, and spinach. It gave the following response.</p>
<pre tabindex="0"><code>Dish Name: Spinach and Eggplant Rice Casserole
Ingredients: …
</code></pre><p>Great! But now it appears there is another problem. Since it simply outputs text, there is no proper way to parse the text to extract the required information. Like the name of the dish, list of the ingredients, etc. This is because, if I send the same prompt again, the decoder of the LLM will again perform sampling, which being probabilistic, may end up a bit differently. It can now start with “Here is a dish that you can make with … ingredients. The name of the dish is …”</p>
<p>So, to make the response from the LLM helpful for your software/use case, you need something more. A bit more specially tailored prompt.</p>
<p>Provide a step-by-step guide on how to prepare a delicious dish based on the ingredients which I list down below. Please respond in the following exact format shown below.</p>
<pre tabindex="0"><code>&lt;dish&gt;The name of the dish&lt;/dish&gt;
&lt;ingredients&gt;
&lt;ingredient&gt;&lt;name&gt;Name of the ingredient used&lt;/name&gt;&lt;quantity&gt;The quantity of the ingredient&lt;/quantity&gt;&lt;/ingredient&gt;
...
&lt;/ingredients&gt;
&lt;cooking_time&gt;Provide the approximate cooking time in minutes.&lt;/cooking_time&gt;
&lt;receipe&gt;
A markdown text explaining the step-by-step process on how to prepare the dish.
&lt;/receipe&gt;
<p>Also make sure the dish has nutritional value.
Here are the list of available ingredients:
{list of ingredients}
</code></pre><p>Here, we rewrite the same prompt, but this time, we specifically instructed the LLM to adhere to a specific format. This time, the same LLM always replied in this format.</p></p>
<pre tabindex="0"><code>&lt;dish&gt;Spinach and Eggplant Rice Casserole&lt;/dish&gt;
&lt;ingredients&gt;
 &lt;ingredient&gt;&lt;name&gt;Rice&lt;/name&gt;&lt;quantity&gt;1 cup&lt;/quantity&gt;&lt;/ingredient&gt;
 &lt;ingredient&gt;&lt;name&gt;Eggplant&lt;/name&gt;&lt;quantity&gt;1 medium-sized, diced&lt;/quantity&gt;&lt;/ingredient&gt;
 ...
&lt;/ingredients&gt;
&lt;cooking_time&gt;60 minutes&lt;/cooking_time&gt;
&lt;receipe&gt;
1. Prepare the rice 
...
&lt;/receipe&gt;
</code></pre><p>One interesting thing to note here is that I intentionally spelled <recipe> wrong using <receipe>. This is just to demonstrate that the LLM copies it exactly without the meaning attached to the name of the tags.</p>
<p>Usually, asking the LLM to write values within XML tags (like the ones in the angled bracket) works great to ensure a reliable LLM workflow. Now when the LLM returns the output in this specific format, you can parse the text and retrieve the exact information you need using Regex. (Think of this as a sophisticated algorithm for string matching).</p>
<p>So, now your software using the LLM intelligence looks like this: Basically, the output from the LLM now goes through different parsers (like Regex matching) which feed the required information to your application code, which can respond to the user, by leverage the intelligence of the LLM.</p>
<div class="mermaid">
graph LR
    User <--> ApplicationCode[Application Code]
    ApplicationCode --> Variable
    ApplicationCode --> Template
    Variable --> Prompt
    Template --> Prompt
    Prompt --> LLM
    LLM --> Output
    Output --> Parser1[Parser 1]
    Output --> Parser2[Parser 2]
    Output --> Ellipsis[...]
    Output --> ParserN[Parser n]
    Parser1 --> ApplicationCode
    Parser2 --> ApplicationCode
    ParserN --> ApplicationCode
    Ellipsis --> ApplicationCode
</div>
<h3 id="system-prompts">System Prompts</h3>
<p>Now this kind of templating architecture for using LLM has become a norm, so, the major AI companies (e.g. Meta, Anthropic, OpenAI, etc.) started integrating this system into the model itself. Remember that we had training documents looking like User: Question and then Assistant: Answer format for training the LLM. Now, a variant of the training document was introduced.</p>
<pre tabindex="0"><code>System: You will always answer the user’s query in Spanish.
User: What is the capital of France?
Assistant: La capital de Francia es París
User: Which visiting places should I go to in Paris?
Assistant: Éstos son algunos de los principales lugares recomendados para visitar en París: 1. Torre Effiel. 2. Museo del Louvre. 3. Catedral de Notre Dame,…
</code></pre><p>Basically, now at the beginning of the training document, it introduces a system prompt that determines how the chatbot will behave. It is like providing most parts of your template whatever is static. The user query will contain only the rest dynamic part that will come from the user inputs.</p>
<p>It should be obvious to you now that the system prompt is also a part of the prompt. Hence, whenever you use the LLM, they charge you exactly the same way for the system prompt tokens also. It is internally, they format this sequence of System: , User: and Assistant: dialogues and then ask the LLM to autocomplete that dialogue.</p>
<p>Hence, if you have $100$ tokens (words) in the system prompt and the user types in a query with 50 tokens, then you are charged for $150$ tokens (sometimes may be $5$ more tokens, i.e., $155$ tokens, as it includes <SYS><TEM>&lt;:&gt; and <USER>&lt;:&gt;)</p>
<h2 id="conclusion">Conclusion</h2>
<p>So far, we have seen different prompting techniques to make effective use of LLM. But still, one major problem persists. It is that all LLM, so far, under the hood is an autocomplete model that works by predicting the next best word to finish the sentence. Clearly, it does not mean that the “best” word is always the correct answer.</p>
<ul>
<li>
<p><code>The earth is ____.</code> The “best” word might be round, beautiful, massive, etc. But it is really very unlikely to continue this sentence as “The earth is composed of minerals like … &ldquo;, which might be the correct answer given the context.</p>
</li>
<li>
<p><code>___ is a doctor. ___ is a nurse.</code> Usually, most of the training data (results on the internet) will contain “He is a doctor. She is a nurse”. But this, in principle, reflects the gender bias present in most open-access texts, while the other way around “She is a doctor. He is a nurse” is equally valid.</p>
</li>
</ul>
<p>This phenomenon is called the <strong>Hallucination Effect</strong> on the LLM, where the LLM outputs a very probable but wrong answer. In the next post, we will explore this direction and see the popular ideas that can be used to mitigate this.</p>
<p>Thank you very much for being a valued reader! 🙏🏽 Stay tuned for upcoming posts on the Generative AI series. Subscribe to my newsletter <a href="https://statwizard.substack.com/?showWelcome=true">here</a> to get notified when the next post is out. 📢</p>
<p>Until next time.</p>

                </div>
            </div>
        </div>
    </div>
    <div class="flex flex-row justify-center items-center mb-3">
        <h2 class="text-lg text-blue-600">
            With heartfelt appreciation, thank you for being a valued reader, until next time!
        </h2>
    </div>
</div>



<div class="my-6 max-w-6xl md:mx-auto mx-4 text-center shadow-md rounded-md p-4">
    <p class="italic text-lg font-semibold my-4">Explore more posts like this</p>
    <div class="flex flex-row justify-center gap-4">
        
            <a href="//localhost:1313/posts/2024/generative-ai-encoder-decoder/" 
                class="px-6 py-2 bg-blue-800 text-white hover:bg-neutral-900 focus:bg-neutral-900 
                    transition-all ease-in-out rounded-md shadow-sm">
                Previous Post
            </a>
        
        
            <a href="//localhost:1313/posts/2024/making-most-from-prompts/" class="px-6 py-2 bg-blue-800 text-white hover:bg-neutral-900
             focus:bg-neutral-900 transition-all ease-in-out rounded-md shadow-sm">
                Next Post
            </a>
        
    </div>
    <div class="flex flex-row justify-center gap-4 my-4">
        <a href="//localhost:1313/posts/" 
            class="px-6 py-2 bg-blue-800 text-white hover:bg-neutral-900 focus:bg-neutral-900 
                transition-all ease-in-out rounded-md shadow-sm">
            See all posts
        </a>
    </div>
</div>


<div class="my-6 max-w-6xl md:mx-auto mx-4">
    <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "statwizard" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>



      </div>
    </div>

    <script>
    $(document).ready(() => {

        
        $('#mobile-menu-button').click(() => {
            $('#mobile-menu').toggleClass('hidden');
            $('#mobile-menu-close-icon').toggleClass('hidden');
            $('#mobile-menu-close-icon').toggleClass('block');
            $('#mobile-menu-open-icon').toggleClass('hidden');
            $('#mobile-menu-open-icon').toggleClass('block');
        });

    });
</script>


<script async src="https://kit.fontawesome.com/ca14d5004b.js" crossorigin="anonymous"></script>
 
    


    <script type="module" defer>
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
        mermaid.initialize({ startOnLoad: true, securityLevel: "loose" });
    </script>



    
    <script defer>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js"></script>



  </body>
</html>
